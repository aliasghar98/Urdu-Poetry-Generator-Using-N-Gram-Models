{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "i18-0475.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing SpaCy.** "
      ],
      "metadata": {
        "id": "aKeWyoJOq0A2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import spacy\r\n",
        "unlp = spacy.blank('ur')"
      ],
      "outputs": [],
      "metadata": {
        "id": "Vm8ykqGWryaV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading the corpus.**"
      ],
      "metadata": {
        "id": "PypqEnAMs4jD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note : Please upload the files before executing the code."
      ],
      "metadata": {
        "id": "fN2-w0aR63Yg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#Uploaded the three text files manually.\r\n",
        "faiz_corpus = open('faiz.txt').read()\r\n",
        "ghalib_corpus = open('ghalib.txt').read()\r\n",
        "iqbal_corpus = open('iqbal.txt').read()\r\n",
        "total_corpus = faiz_corpus + ghalib_corpus + iqbal_corpus"
      ],
      "outputs": [],
      "metadata": {
        "id": "N61rKW1vs7vQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# faiz_text = unlp(faiz_corpus)\r\n",
        "# ghalib_text = unlp(ghalib_corpus)\r\n",
        "# iqbal_text = unlp(iqbal_corpus)"
      ],
      "outputs": [],
      "metadata": {
        "id": "ziSk2SHlWvaO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generating sentences**"
      ],
      "metadata": {
        "id": "IN7mEc0sdwSR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "faiz_sentences = faiz_corpus.splitlines()\r\n",
        "ghalib_sentences = ghalib_corpus.splitlines()\r\n",
        "iqbal_sentences = iqbal_corpus.splitlines()"
      ],
      "outputs": [],
      "metadata": {
        "id": "Y2teLjGlWvdW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentences are separated based on spaces. After that, we removed any unnecessary punctuation as can be seen below and make a list of sentences."
      ],
      "metadata": {
        "id": "s3ZUk0pJxeqa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# punctuation = \"؟!‘’:“''۔،\"\r\n",
        "punctuation = ['،','۔',\"''\",'“',':','’','‘','!','؟',')','(']\r\n",
        "faiz_sentences = [sentence if sentence != ' ' else None for sentence in faiz_sentences]\r\n",
        "faiz_sentences = list(filter(None,faiz_sentences))\r\n",
        "for i in punctuation:\r\n",
        "  faiz_sentences = [sentence.replace(i, '') for sentence in faiz_sentences]\r\n",
        "\r\n",
        "ghalib_sentences = [sentence if sentence != ' ' else None for sentence in ghalib_sentences]\r\n",
        "ghalib_sentences = list(filter(None,ghalib_sentences))\r\n",
        "for i in punctuation:\r\n",
        "  ghalib_sentences = [sentence.replace(i, '') for sentence in ghalib_sentences]\r\n",
        "\r\n",
        "iqbal_sentences = [sentence if sentence != ' ' else None for sentence in iqbal_sentences]\r\n",
        "iqbal_sentences = list(filter(None,iqbal_sentences))\r\n",
        "for i in punctuation:\r\n",
        "  iqbal_sentences = [sentence.replace(i, '') for sentence in iqbal_sentences]\r\n",
        "\r\n",
        "print(\"Number of Faiz Sentences : \",len(faiz_sentences))\r\n",
        "print(\"Number of Ghalib Sentences : \",len(ghalib_sentences))\r\n",
        "print(\"Number of Iqbal Sentences : \",len(iqbal_sentences))\r\n",
        "total_sentences = faiz_sentences + ghalib_sentences + iqbal_sentences"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_QPpNQoWvn0",
        "outputId": "2b40a6e4-ada0-4c4a-b1c2-ee97db9b08c2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generating words.**"
      ],
      "metadata": {
        "id": "X4JEk5oFro8y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We separate each word based on the spaces and generate a list of words of one sentence. \"total_words\" is a list of sentences, and each list of sentences has a list of words inside it. "
      ],
      "metadata": {
        "id": "KnDlM6VDxuea"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "faiz_words = list()\r\n",
        "ghalib_words = list()\r\n",
        "iqbal_words = list()\r\n",
        "\r\n",
        "for word in faiz_sentences:\r\n",
        "  faiz_words.append(word.split(' '))\r\n",
        "for word in ghalib_sentences:\r\n",
        "  ghalib_words.append(word.split(' '))\r\n",
        "for word in iqbal_sentences:\r\n",
        "  iqbal_words.append(word.split(' '))\r\n",
        "flat_list_faiz = [item for sublist in faiz_words for item in sublist]\r\n",
        "flat_list_ghalib = [item for sublist in ghalib_words for item in sublist]\r\n",
        "flat_list_iqbal = [item for sublist in iqbal_words for item in sublist]\r\n",
        "print(\"Number of words in Faiz : \", len(flat_list_faiz))\r\n",
        "print(\"Number of words in Ghalib : \", len(flat_list_ghalib))\r\n",
        "print(\"Number of words in Iqbal : \", len(flat_list_iqbal))\r\n",
        "flat_list_words = len(flat_list_faiz) + len(flat_list_ghalib) + len(flat_list_iqbal) \r\n",
        "total_words = faiz_words + ghalib_words + iqbal_words"
      ],
      "outputs": [],
      "metadata": {
        "id": "BEbPI2TXnyNy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d7d4108-877d-48d9-87ea-51d29bc6973d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generating Unigram Model**"
      ],
      "metadata": {
        "id": "pjuXokmD1_ZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this task, I have firstly taken out the number of occurrences of each word separately and stored that in a dictionary called \"wordOccurences\"."
      ],
      "metadata": {
        "id": "HGrcO3XGyBrw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "wordOccurences = dict()\r\n",
        "for sentence in total_words:\r\n",
        "  for word in sentence:\r\n",
        "    if word not in wordOccurences:\r\n",
        "      wordOccurences[word] = 1\r\n",
        "    else:\r\n",
        "      wordOccurences[word] += 1\r\n",
        "tempWO = sorted(wordOccurences,key=wordOccurences.get,reverse = True)\r\n",
        "# totalWords = 0\r\n",
        "# for i in tempWO: \r\n",
        "#   print(\"Word : \", i, \" occurences : \" , wordOccurences[i])\r\n",
        "#   totalWords += wordOccurences[i]\r\n",
        "# print(\"total words : \", totalWords)"
      ],
      "outputs": [],
      "metadata": {
        "id": "-WVkDrWa2CqC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next I have divided the occurences of each word with the number of total words in the dataset, because if I instead used the conditional probability formula, I would've always gotten '1.0' as the probability."
      ],
      "metadata": {
        "id": "7M3Tfilryhnr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "unigrams = dict()\r\n",
        "for key, value in wordOccurences.items():\r\n",
        "  unigrams[key] = (value / flat_list_words)\r\n",
        "sortedUnigrams = sorted(unigrams,key=unigrams.get,reverse = True)\r\n",
        "# for i in tempUnigrams:\r\n",
        "#  print(\"Word : \", i, \" probability : \" , unigrams[i])"
      ],
      "outputs": [],
      "metadata": {
        "id": "Yz2seKXDkqa9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have found the list of first and last words too here."
      ],
      "metadata": {
        "id": "Ln7TfOkezEvR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import random\r\n",
        "first_words = list()\r\n",
        "last_words = list()\r\n",
        "for sentence in total_words:\r\n",
        "  first_words.append(sentence[0])\r\n",
        "  last_words.append(sentence[len(sentence)-1])"
      ],
      "outputs": [],
      "metadata": {
        "id": "RfncWkFtxpGg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I generate the Stanzas. I select the first word randomly from the list of first words and then I choose subsequent words randomly from the list of unigrams. This is completely random and the verses don't make any actual sense hence this model is not very effective."
      ],
      "metadata": {
        "id": "VX0xBQmbzIAD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def GenerateUnigramStanza():\r\n",
        "  stanzaList = list()\r\n",
        "  # print(\"Length : \", length)\r\n",
        "  for stanzaCount in range(0,3):\r\n",
        "    stanza = list()\r\n",
        "    for i in range(0,4):\r\n",
        "      length = random.randint(7,10)\r\n",
        "      firstWord = random.choice(first_words)\r\n",
        "      # print(\"First word : \", firstWord)\r\n",
        "      verse = str()\r\n",
        "      verse = verse + firstWord\r\n",
        "      verse = verse + \" \"\r\n",
        "      for j in range(1,length):\r\n",
        "        word = random.choice(list(unigrams.keys()))\r\n",
        "        # print(\"random word : \", word)\r\n",
        "        verse = verse + word\r\n",
        "        verse = verse + \" \"\r\n",
        "      stanza.append(verse)\r\n",
        "    stanzaList.append(stanza)\r\n",
        "    stanzaList.append(\"\\n\") \r\n",
        "  return stanzaList\r\n",
        "\r\n",
        "unigramStanzas = GenerateUnigramStanza()\r\n",
        "for stanza in unigramStanzas:\r\n",
        "  for verse in stanza: \r\n",
        "    print(verse)"
      ],
      "outputs": [],
      "metadata": {
        "id": "WuLJ560M2di5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0894e9d7-7d96-4c76-a485-fce313b62196"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generating Bigram Model**"
      ],
      "metadata": {
        "id": "8GkeOP6qcuDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly I find all the bigrams."
      ],
      "metadata": {
        "id": "GbzI96r-0ChN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "bigramsList = list()\r\n",
        "for sentence in total_words:\r\n",
        "  for i in range(len(sentence)-1):\r\n",
        "    w1 = sentence[i]\r\n",
        "    w2 = sentence[i+1]\r\n",
        "    bigramsList.append(tuple((w1,w2)))\r\n",
        "# for x in bigramsList:\r\n",
        "#   print(x[0],x[1])"
      ],
      "outputs": [],
      "metadata": {
        "id": "_Gd2DGmebGPC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then I take out all the occurrences of each bigram respectively and store it in a dictionary called \"bigramsOccurrences\"."
      ],
      "metadata": {
        "id": "KKNpRqI_0F5Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "bigramsOccurrences = dict()\r\n",
        "for bigram in bigramsList:\r\n",
        "    if bigram not in bigramsOccurrences:\r\n",
        "      bigramsOccurrences[bigram] = 1\r\n",
        "    else:\r\n",
        "      bigramsOccurrences[bigram] += 1\r\n",
        "# bigramsOccurrences"
      ],
      "outputs": [],
      "metadata": {
        "id": "gqD8PLz8j2RU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each bigram, I find out it's conditional probability over here and sort them on the basis of their probabilities in a list."
      ],
      "metadata": {
        "id": "NKFvWSSk0MGQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "bigrams = dict()\r\n",
        "for key, value in bigramsOccurrences.items(): # value = count(w1,w2)\r\n",
        "  denom = wordOccurences[key[0]]\r\n",
        "  bigrams[key] = (value / denom)\r\n",
        "  # print(key[0],key[1])\r\n",
        "sortedBigrams = sorted(bigrams,key=bigrams.get,reverse = True)\r\n",
        "# for i in sortedBigrams:\r\n",
        "#   print(\"Bigram : \", i, \" probability : \" , bigrams[i])"
      ],
      "outputs": [],
      "metadata": {
        "id": "Qx0qhKB1mJRo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here I generate the actual stanzas. For this, firstly I pick a random starting word for the sentences from the list of first words. Then I use that word as the context to generate the next word, and then the next word to generate the third word and so on... Thus using each newly generated word to generate the word after it. In the case where no bigram exists for the preceding word i.e. the preceding word was a 'last word' then we randomly select any word from the top 10 unigrams. This is by far a better method than Unigrams as the verses generated make some sense compared to the completely random verses generated by unigrams that often do not make any sense at all."
      ],
      "metadata": {
        "id": "sKXTECiJ0S5-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def getPredictedNextWords(word) -> list:\r\n",
        "  predictedWords = dict()\r\n",
        "  for key,value in bigrams.items():\r\n",
        "    if key[0] == word:\r\n",
        "      predictedWords[key[1]] = value\r\n",
        "  sortedWords = sorted(predictedWords,key=predictedWords.get,reverse = True)\r\n",
        "  if len(sortedWords) > 10:\r\n",
        "    sortedWords = sortedWords[:10]\r\n",
        "  if len(sortedWords) == 0:#If no bigram found i.e last word.\r\n",
        "    sortedWords = sortedUnigrams[:10]\r\n",
        "  return sortedWords\r\n",
        "\r\n",
        "def GenerateBigramStanza(): \r\n",
        "  stanzaList = list()\r\n",
        "  # print(\"Length : \", length)\r\n",
        "  for stanzaCount in range(0,3):\r\n",
        "    stanza = list()\r\n",
        "    for i in range(0,4):\r\n",
        "      length = random.randint(7,10)\r\n",
        "      firstWord = random.choice(first_words)\r\n",
        "      # print(\"First word : \", firstWord)\r\n",
        "      verse = str()\r\n",
        "      verse = verse + firstWord\r\n",
        "      verse = verse + \" \"\r\n",
        "      tempWord = firstWord\r\n",
        "      for j in range(1,length):\r\n",
        "        word = random.choice(getPredictedNextWords(tempWord))\r\n",
        "        verse = verse + word\r\n",
        "        verse = verse + \" \"\r\n",
        "        tempWord = word\r\n",
        "        # print(\"Temp word : \", word)\r\n",
        "      stanza.append(verse)\r\n",
        "    stanzaList.append(stanza)\r\n",
        "    stanzaList.append(\"\\n\") \r\n",
        "  return stanzaList\r\n",
        "\r\n",
        "bigramStanzas = GenerateBigramStanza()\r\n",
        "for stanza in bigramStanzas:\r\n",
        "  for verse in stanza: \r\n",
        "    print(verse)"
      ],
      "outputs": [],
      "metadata": {
        "id": "oKAexHoYpT5t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71a1eb01-c1f2-4e78-9e03-8b6a0703e8ad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generating Trigram Model**"
      ],
      "metadata": {
        "id": "r7Vd4o9TrJP9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly we find all the trigrams."
      ],
      "metadata": {
        "id": "DBgfSoD8223x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "trigramsList = list()\r\n",
        "for sentence in total_words:\r\n",
        "  for i in range(len(sentence)-2):\r\n",
        "    w1 = sentence[i]\r\n",
        "    w2 = sentence[i+1]\r\n",
        "    w3 = sentence[i+2]\r\n",
        "    trigramsList.append(tuple((w1, w2, w3)))\r\n",
        "  \r\n",
        "# for x in trigramsList[:20]:\r\n",
        "#   print(x[0], x[1], x[2])"
      ],
      "outputs": [],
      "metadata": {
        "id": "YyKsgEevrM9V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we find each trigram's occurrences respectively and save it into a dictionary."
      ],
      "metadata": {
        "id": "vk6_KyTf25hj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "trigramsOccurrences = dict()\r\n",
        "for trigram in trigramsList:\r\n",
        "    if trigram not in trigramsOccurrences:\r\n",
        "      trigramsOccurrences[trigram] = 1\r\n",
        "    else:\r\n",
        "      trigramsOccurrences[trigram] += 1\r\n",
        "# trigramsOccurrences"
      ],
      "outputs": [],
      "metadata": {
        "id": "PBV7p0fGrY71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we calculate the conditional probability by finding the count of the bigram within the trigram and save this information in a dictionary and sort it."
      ],
      "metadata": {
        "id": "v3bLNMJO2_U0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "trigrams = dict()\r\n",
        "for key, value in trigramsOccurrences.items(): # Value = count(w1,w1,w3)\r\n",
        "  denom = bigramsOccurrences[key[:2]]\r\n",
        "  trigrams[key] = (value / denom)\r\n",
        "  # print(key[0],key[1])\r\n",
        "sortedTrigrams = sorted(trigrams,key=trigrams.get,reverse = True)\r\n",
        "# for i in sortedTrigrams:\r\n",
        "#   print(\"Trigram : \", i, \" probability : \" , trigrams[i])"
      ],
      "outputs": [],
      "metadata": {
        "id": "EomhG5aUyHPP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we will generate the actual stanzas. We select the first word randomly from the list of first words and get the second word from the list of bigrams randomly. Then on the basis of these two words, we generate the third word of the trigram randomly from the possibilities. After doing this, we use the second word and the newly generated word to generate the next word and this process carries on... Until all the subsequent words for the verse have been found. In the case where no third word is found for the preceding words i.e. the last two words are part of the end of the sentence, we randomly select a word from the top 10 unigrams. This is the most effective way thus far as most of the verses make actual sense and the context of the verses can be understood."
      ],
      "metadata": {
        "id": "IppbRlB53MCc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def getTrigramsPredictedNextWords(w1,w2) -> list:\r\n",
        "  predictedWords = dict()\r\n",
        "  for key,value in trigrams.items():\r\n",
        "    if key[0] == w1 and key[1] == w2:\r\n",
        "      predictedWords[key[2]] = value\r\n",
        "  sortedWords = sorted(predictedWords,key=predictedWords.get,reverse = True)\r\n",
        "  if len(sortedWords) > 10:\r\n",
        "    sortedWords = sortedWords[:10]\r\n",
        "  if len(sortedWords) == 0:#If no trigram found i.e last word.\r\n",
        "    sortedWords = sortedUnigrams[:10]\r\n",
        "  return sortedWords\r\n",
        "\r\n",
        "def GenerateTrigramStanza(): \r\n",
        "  stanzaList = list()\r\n",
        "  # print(\"Length : \", length)\r\n",
        "  for stanzaCount in range(0,3):\r\n",
        "    stanza = list()\r\n",
        "    for i in range(0,4):\r\n",
        "      length = random.randint(7,10)\r\n",
        "      firstWord = random.choice(first_words)\r\n",
        "      secondWord = random.choice(getPredictedNextWords(firstWord))\r\n",
        "      # print(\"First word : \", firstWord)\r\n",
        "      verse = str()\r\n",
        "      verse = verse + firstWord\r\n",
        "      verse = verse + \" \"\r\n",
        "      verse = verse + secondWord\r\n",
        "      verse = verse + \" \"\r\n",
        "      tempWord1 = firstWord\r\n",
        "      tempWord2 = secondWord\r\n",
        "      for j in range(2,length):\r\n",
        "        word = random.choice(getTrigramsPredictedNextWords(tempWord1,tempWord2))\r\n",
        "        verse = verse + word\r\n",
        "        verse = verse + \" \"\r\n",
        "        tempWord1 = tempWord2\r\n",
        "        tempWord2 = word\r\n",
        "        # print(\"Temp word : \", word)\r\n",
        "      stanza.append(verse)\r\n",
        "    stanzaList.append(stanza)\r\n",
        "    stanzaList.append(\"\\n\") \r\n",
        "  return stanzaList\r\n",
        "\r\n",
        "\r\n",
        "trigramStanzas = GenerateTrigramStanza()\r\n",
        "for stanza in trigramStanzas:\r\n",
        "  for verse in stanza: \r\n",
        "    print(verse)"
      ],
      "outputs": [],
      "metadata": {
        "id": "eRuRnpvR2ioj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48c4fac7-30f9-4f9b-b718-9ae17c3d0644"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generating Backward Bigram Model**"
      ],
      "metadata": {
        "id": "6W-59oqLD_m-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the same bigrams we generated before for backward bigram model. To generate Stanzas, instead of selecting a first word randomly, we will select a last word randomly. Using that last word, we will find the possible words preceding it and select any one randomly. We will repeat this process by using each randomly selected preceding word to select the subsequent preceding word until we have the whole verse. Lastly we will reverse the verse and append it to our stanza. This is pretty much the same thing we did for Bigram Model. The method is same, it's just that the direction of the context has been changed."
      ],
      "metadata": {
        "id": "QeyDEeXW4VQU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def getBackwardBigramPredictedNextWord(word) -> list:\n",
        "  predictedWords = dict()\n",
        "  for key,value in bigrams.items():\n",
        "    if key[1] == word:\n",
        "      predictedWords[key[0]] = value\n",
        "  sortedWords = sorted(predictedWords,key=predictedWords.get,reverse = True)\n",
        "  if len(sortedWords) > 10:\n",
        "    sortedWords = sortedWords[:10]\n",
        "  if len(sortedWords) == 0:#If no bigram found i.e last word.\n",
        "    sortedWords = sortedUnigrams[:10]\n",
        "    print()\n",
        "  return sortedWords\n",
        "\n",
        "def GenerateBackwardBigramStanza(): \n",
        "  stanzaList = list()\n",
        "  # print(\"Length : \", length)\n",
        "  for stanzaCount in range(0,3):\n",
        "    stanza = list()\n",
        "    for i in range(0,4):\n",
        "      length = random.randint(7,10)\n",
        "      lastWord = random.choice(last_words)\n",
        "      # print(\"Last word : \", lastWord)\n",
        "      verse = str()\n",
        "      verse = verse + lastWord\n",
        "      verse = verse + \" \"\n",
        "      tempWord = lastWord\n",
        "      for j in range(1,length):\n",
        "        word = random.choice(getPredictedNextWords(tempWord))\n",
        "        verse = verse + word\n",
        "        verse = verse + \" \"\n",
        "        tempWord = word\n",
        "        # print(\"Temp word : \", word)\n",
        "      verseWords = verse.split()\n",
        "      verseWords = list(reversed(verseWords))\n",
        "      reversedVerse = str()\n",
        "      for w in verseWords:\n",
        "        reversedVerse = reversedVerse + w\n",
        "        reversedVerse = reversedVerse + \" \"\n",
        "      stanza.append(reversedVerse)\n",
        "    stanzaList.append(stanza)\n",
        "    stanzaList.append(\"\\n\") \n",
        "  return stanzaList\n",
        "\n",
        "\n",
        "backwardBigramStanzas = GenerateBackwardBigramStanza()\n",
        "for stanza in backwardBigramStanzas:\n",
        "  for verse in stanza: \n",
        "    print(verse)"
      ],
      "outputs": [],
      "metadata": {
        "id": "j6_5GfkzF9Br",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cf4d6cc-0b55-49a4-f013-ca8fe458c3fd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generating Bidirectional Bigram Model**"
      ],
      "metadata": {
        "id": "8t90tcYiTbWN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use the same list of bigrams for this too. To generate stanzas, we will select a first word and a last word randomly. We will apply the same Bigram Model to the first word and the Backward Bigram Model to the last word. Thus we will generate our verse from the ends till the middle. Half of the verse will be generated by Backward Bigram Model and half from Bigram Model. This combines both the Bigram and Backward Bigram Models and is thus a combination of them both. No noticeable difference can be seen between between this or the Bigram Model and the Backward Bigram Model."
      ],
      "metadata": {
        "id": "cZilzssg47XD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def GenerateBidirectionalBigramStanza(): \n",
        "  stanzaList = list()\n",
        "  # print(\"Length : \", length)\n",
        "  for stanzaCount in range(0,3):\n",
        "    stanza = list()\n",
        "    for i in range(0,4):\n",
        "      length = random.randint(7,10)\n",
        "      firstWord = random.choice(first_words)\n",
        "      lastWord = random.choice(last_words)\n",
        "      # print(\"First word : \", firstWord)\n",
        "      # print(\"Last word : \", lastWord)\n",
        "      verse = str()\n",
        "      verse1 = str()\n",
        "      verse2 = str()\n",
        "      verse1 = verse1 + firstWord\n",
        "      verse1 = verse1 + \" \"\n",
        "      verse2 = verse2 + lastWord\n",
        "      verse2 = verse2 + \" \"\n",
        "      tempWord1 = firstWord\n",
        "      tempWord2 = lastWord\n",
        "      if length%2 == 0: #Even length.\n",
        "        # print(\"EVEN LENGTH\")\n",
        "        for j in range(1,length//2): \n",
        "          word = random.choice(getPredictedNextWords(tempWord1))\n",
        "          verse1 = verse1 + word\n",
        "          verse1 = verse1 + \" \"\n",
        "          tempWord1 = word\n",
        "        for k in range(1,length//2):\n",
        "          word = random.choice(getBackwardBigramPredictedNextWord(tempWord2))\n",
        "          verse2 = verse2 + word\n",
        "          verse2 = verse2 + \" \"\n",
        "          tempWord2 = word\n",
        "      elif length%2 == 1:\n",
        "        # print(\"ODD LENGTH\")\n",
        "        for j in range(1,(length//2) +1):\n",
        "          word = random.choice(getPredictedNextWords(tempWord1))\n",
        "          verse1 = verse1 + word\n",
        "          verse1 = verse1 + \" \"\n",
        "          tempWord1 = word\n",
        "        for k in range(1,length//2):\n",
        "          word = random.choice(getBackwardBigramPredictedNextWord(tempWord2))\n",
        "          verse2 = verse2 + word\n",
        "          verse2 = verse2 + \" \"\n",
        "          tempWord2 = word\n",
        "      verseWords = verse2.split()\n",
        "      verseWords = list(reversed(verseWords))\n",
        "      reversedVerse = str()\n",
        "      for w in verseWords:\n",
        "        reversedVerse = reversedVerse + w\n",
        "        reversedVerse = reversedVerse + \" \"\n",
        "      verse = verse1 + reversedVerse\n",
        "      # print(\"Forward Verse : \", verse1)\n",
        "      # print(\"Backward Verse : \", reversedVerse)\n",
        "      stanza.append(verse)\n",
        "    stanzaList.append(stanza)\n",
        "    stanzaList.append(\"\\n\")\n",
        "  return stanzaList\n",
        "\n",
        "bidirectionalBigramStanzas = GenerateBidirectionalBigramStanza()\n",
        "for stanza in bidirectionalBigramStanzas:\n",
        "  for verse in stanza: \n",
        "    print(verse)"
      ],
      "outputs": [],
      "metadata": {
        "id": "uLKYLPsDd_EC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa88a09f-7dc2-427f-e9d3-7e96944a17d4"
      }
    }
  ]
}